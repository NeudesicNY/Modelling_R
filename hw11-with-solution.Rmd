---
title: 'CSCI E-63C Week 11 assignment: solution'
output:
  html_document:
    toc: true
---

```{r setup, include=FALSE}
library(ISLR)
library(e1071)
library(randomForest)
library(class)
library(ggplot2)
library(reshape2)
library(plyr)
knitr::opts_chunk$set(echo = TRUE)
```


# Preface

This week assignment will explore behavior of support vector classifiers and SVMs (following the distinction made in ISLR) on banknote authentication dataset from UCI ML archive.  We worked with it on multiple occasions before (most recently two weeks ago evaluating performance of logistic regression, discriminant analysis and KNN on it):

```{r dbaExample}
dbaDat <- read.table("data_banknote_authentication.txt",sep=",")
colnames(dbaDat) <- c("var","skew","curt","entr","auth")
dbaDat$auth <- factor(dbaDat$auth)
dim(dbaDat)
summary(dbaDat)
head(dbaDat)
pairs(dbaDat[,1:4],col=as.numeric(dbaDat$auth))
```

Here we will use SVM implementation available in library `e1071` to fit classifiers with linear and radial (polynomial for extra points) kernels and compare their relative performance as well as to that of random forest and KNN.

# Problem 1 (20 points): support vector classifier (i.e. using linear kernel) 

Use `svm` from library `e1071` with `kernel="linear"` to fit classifier (e.g. ISLR Ch.9.6.1) to the entire banknote authentication dataset setting parameter `cost` to 0.001, 1, 1000 and 1 mln.  Describe how this change in parameter `cost` affects model fitting process (hint: the difficulty of the underlying optimization problem increases with cost -- can you explain what drives it?) and its outcome (how does the number of support vectors change with `cost`?) and what are the implications of that.  Explain why change in `cost` value impacts number of support vectors found. (Hint: there is an answer in ISLR.)  Use `tune` function from library `e1071` (see ISLR Ch.9.6.1 for details and examples of usage) to determine approximate value of cost (in the range between 0.1 and 100 -- the suggested range spanning orders of magnitude should hint that the density of the grid should be approximately logarithmic -- e.g. 1, 3, 10, ... or 1, 2, 5, 10, ... etc.) that yields the lowest error in cross-validation employed by `tune`.  Setup a resampling procedure repeatedly splitting entire dataset into training and test, using training data to `tune` cost value and test dataset to estimate classification error. Report and discuss distributions of test errors from this procedure and selected values of `cost`.

## Solution

```{r svmLin4costs}
svm(auth~.,data=dbaDat,kernel="linear",cost=0.001)
svm(auth~.,data=dbaDat,kernel="linear",cost=1)
svm(auth~.,data=dbaDat,kernel="linear",cost=1000)
svm(auth~.,data=dbaDat,kernel="linear",cost=1000000)
```

Parameter `cost` in the call to `svm` is inversely related to the constant $C$ in the ISLR formulation of optimization problem as in Eq.9.12-9.15 (compare to $\lambda$ in Eq.9.25; see also original documentation for LIBSVM library cited in `svm` help).  The high values of `cost` correspond to low values of $C$ in ISLR formulation, i.e. low "budget" for margin violation in terms of the sum of slack variables $\epsilon_i \geq 0$, narrow margin $M$ and small number of support vectors (i.e. observations within or on the wrong side of margin) (see ISRL Ch.9.2.2 for details).  In the above examples we can see how changing cost over nine orders of magnitude changes number of support vectors from over a thousand (i.e. most of the observations in the dataset -- for the lowest value of `cost=0.001`) to about a couple of dozen (for the highest value of `cost=1000` that still allows the optimizer to find suitable solution).  Use of `cost=1000000` makes corresponding optimization problem so hard that it does not converge in the allotted number of iterations.

```{r svmLinTune}
summary(tune(svm,auth~.,data=dbaDat,kernel="linear",ranges=list(cost=c(0.1,0.2,0.5,1,2,5,10,20,50,100))))
summary(tune(svm,auth~.,data=dbaDat,kernel="linear",ranges=list(cost=1:10)))
```

Results from `tune` above suggest that the best model performance on the entire dataset is achieved when `cost` values around 5 are used.

```{r svmLinSim}
dfTmp <- NULL
for ( iSim in 1:10 ) {
  trainIdx <- sample(nrow(dbaDat),nrow(dbaDat),replace=TRUE)
  # linear:
  ##svmTuneRes <- tune(svm,auth~., data=dbaDat[trainIdx,], kernel="linear", ranges=list(cost=c(0.1,0.2,0.5,1,2,5,10,20,50,100)))  ###cost=c(0.5,0.8,1:10,12,15)))
  svmTuneRes <- tune(svm,auth~.,data=dbaDat[trainIdx,],kernel="linear",tunecontrol=tune.control(cross=5),ranges=list(cost=0.5*1.2^(0:21)))   ###1.2^(-1:16)))
  tblTmp <- table(dbaDat[-trainIdx,"auth"],predict(svmTuneRes$best.model,newdata=dbaDat[-trainIdx,]))
  ##print(tblTmp)
  dfTmp <- rbind(dfTmp,data.frame(kernel="linear",attr=c("cost","err0","err1","errTot"),value=c(svmTuneRes$best.parameters[,"cost"],tblTmp[1,2]/sum(tblTmp[1,]),tblTmp[2,1]/sum(tblTmp[2,]),1-sum(diag(tblTmp))/sum(tblTmp))))
}
ggplot(dfTmp,aes(x=attr,y=value))+geom_point(position=position_jitter())+scale_y_log10(breaks=c(0.01,0.1,1,10))
ddply(dfTmp,"attr",function(x)mean(x[,"value"]))
ddply(dfTmp,"attr",function(x)median(x[,"value"]))
```

After choosing parameters for `tune` so that optimal costs are typically within the range of evaluated values and `svm` does not run out of default maximum number of iterations, we can see that typical optimal cost selected on training data is between 1 and 10 and typical test error is close to 1%.

# Problem 2 (10 points): comparison to random forest

Fit random forest classifier on the entire banknote authentication dataset with default parameters.  Calculate resulting misclassification error as reported by the confusion matrix in random forest output.  Explain why error reported in random forest confusion matrix represents estimated test (as opposed to train) error of the procedure.  Compare resulting test error to that for support vector classifier obtained above and discuss results of such comparison.

## Solution

```{r randomForest}
tblTmp <- randomForest(auth~.,dbaDat)$confusion
tblTmp
1-sum(diag(tblTmp[,1:2]))/nrow(dbaDat)
```

Random forest with default parameters results in test (i.e. out-of-bag, OOB) error that is very comparable to that obtained by SVM above.  OOB error represents test error of random forest in the sense that each observation is classified using only those decision trees (from the entire ensemble) that this given observation has not been used to train.  On the other hand, calling random forest again on the same dataset that was used for its training will yield error almost certainly equal to zero in the same sense as KNN with "k=1" would (i.e. highly overfit one).  Each observation on average was included in about 2/3 of the trees in the forest and given that each tree is grown until there is only one observation per leaf, those trees will assign each observation in the input data (when it is the same as training data) its own class from training run of the algorithm:

```{r rfOverFit}
# training error in random forest -- perfect accuracy 
# when training data is provided as input for predict:
table(predict(randomForest(auth~.,dbaDat),newdata=dbaDat),dbaDat$auth)
# why different results from predict when the same data is 
# provided as new data?
table(predict(randomForest(auth~.,dbaDat)),predict(randomForest(auth~.,dbaDat),newdata=dbaDat))
# and on scrambled data as well:
rndDat <- data.frame(apply(dbaDat,2,function(x)as.numeric(sample(x))))
rndDat$auth <- factor(rndDat$auth)
tmpRndRF <- randomForest(auth~.,rndDat)
tmpRndRF$confusion
rndDat <- rndDat[sample(nrow(rndDat)),]
table(predict(tmpRndRF,newdata=rndDat),rndDat$auth)
```


# Extra 7 points problem: effect of `mtry` and `ntree` in random forest

Not directly related to SVM, but while we are at it: fit random forest to the entire banknote authentication dataset for every possible value of parameter `mtry` and using `ntree` of 100 and 1000 for each of them.  The values of `mtry` possible in this case are 1, 2, 3 and 4.  Please explain what is governed by this parameter and why this is the exhaustive set of the values allowed for it in this case. Would it change for another dataset?  What is the default value of `mtry` for this dataset?  Repeat this several times to assess center and spread of the error rates produced by random forest with these parameters across multiple runs of random forest procedure.  Present these results graphically and comment on the impact of the choices of `mtry` and `ntree` on the resulting error rates.

## Solution

```{r rfMtryNtree}
dfTmp <- NULL
for ( iTry in 1:4 ) {
  for ( iTree in c(100,1000) ) {
    for ( iSim in 1:100 ) {
      rfRes <- randomForest(auth~.,dbaDat,ntree=iTree,mtry=iTry)
      dfTmp <- rbind(dfTmp,data.frame(mtry=iTry,ntree=iTree,type=c("0","1","tot"),err=c(rfRes$confusion[,3],sum(rfRes$confusion[,3]*table(dbaDat$auth))/nrow(dbaDat))))
    }
  }
}
ggplot(dfTmp,aes(x=factor(mtry),y=100*err,colour=factor(mtry)))+geom_boxplot()+geom_point(position=position_jitter())+xlab("mtry")+ylab("error, %")+facet_wrap(~ntree+type,ncol=3)
ggplot(ddply(dfTmp,c("mtry","ntree","type"),function(x)sd(x[,'err'])),aes(x=factor(ntree),y=V1))+geom_boxplot(outlier.color = NA)+geom_jitter()+xlab("ntree")+ylab("SD(err)")
```

Random forest parameter `mtry` defines number of variables randomly selected to be evaluated at every split in each decision tree.  For classification procedure its default value is `sqrt(p)` where `p` is the number of predictors in the dataset.  In the case of banknote authentication dataset with `r ncol(dbaDat)-1` predictors, by default `randomForest` will be randomly selecting `r sqrt(ncol(dbaDat)-1)` predictors to choose the best one for each split.  The plots above indicate that variability of error rates decreases with the increase in the number of trees in the forest (as governed by the parameter `ntree`) and choosing the best out of all variables (`mtry=4`) for every split results in higher OOB error -- probably due to decrease in the independence among predictions of the ensemble.

# Problem 3 (10 points): Comparison to cross-validation tuned KNN predictor

Use convenience wrapper `tune.knn` provided by the library `e1071` on the entire dataset to determine optimal value for the number of the nearest neighbors 'k' to be used in KNN classifier.  Consider our observations in week 9 assignment when choosing range of values of `k` to be evaluated by `tune.knn`.  Setup resampling procedure similar to that used above for support vector classifier that will repeatedly: a) split banknote authentication dataset into training and test, b) use `tune.knn` on training data to determine optimal `k`, and c) use `k` estimated by `tune.knn` to make KNN classifications on test data.  Report and discuss distributions of test errors from this procedure and selected values of `k`, compare them to those obtained for random forest and support vector classifier above.

## Solution

```{r knn}
tune.knn(dbaDat[,-ncol(dbaDat)],dbaDat$auth,k=1:10)
tune.knn(dbaDat[,-ncol(dbaDat)],dbaDat$auth,k=1:10)
```

On the entire dataset best `k` in KNN is estimated in the single digits with associated 100% accuracy.

```{r knnSim}
dfTmp <- NULL
for ( iSim in 1:30 ) {
  trainIdx <- sample(nrow(dbaDat),nrow(dbaDat),replace=TRUE)
  knnTuneRes <- tune.knn(dbaDat[trainIdx,-ncol(dbaDat)],dbaDat[trainIdx,ncol(dbaDat)],k=1:10)
  knnTestRes <- knn(dbaDat[trainIdx,-ncol(dbaDat)],dbaDat[-trainIdx,-ncol(dbaDat)],dbaDat[trainIdx,ncol(dbaDat)],k=knnTuneRes$best.parameters[,"k"])
  tblTmp <- table(dbaDat[-trainIdx,"auth"],knnTestRes)
  #print(tblTmp)
  dfTmp <- rbind(dfTmp,data.frame(attr=c("k","err0","err1","errTot"),value=c(knnTuneRes$best.parameters[,"k"],tblTmp[1,2]/sum(tblTmp[1,]),tblTmp[2,1]/sum(tblTmp[2,]),1-sum(diag(tblTmp))/sum(tblTmp))))
}
ggplot(dfTmp,aes(x=attr,y=value))+geom_jitter()+scale_y_log10(breaks=c(0.01,0.1,1,10))
ddply(dfTmp,"attr",function(x)mean(x[,"value"]))
ddply(dfTmp,"attr",function(x)median(x[,"value"]))
```

Over multiple splits of the data into training and test by bootstrap, typically optimal value of nearest neighbors  selected by `tune.knn` was $k=1$, corresponding to test error of less than 0.1% that is even better than what was obtained for SVM with linear kernel and random forest.

# Problem 4 (20 points): SVM with radial kernel

## Sub-problem 4a (10 points): impact of $gamma$ on classification surface

*Plot* SVM model fit to the banknote authentication dataset using (for the ease of plotting) *only variance and skewness* as predictors variables, `kernel="radial"`, `cost=1` and `gamma=1` (see ISLR Ch.9.6.2 for an example of that done with a simulated dataset).  You should be able to see in the resulting plot the magenta-cyan classification boundary as computed by this model.  Produce the same kinds of plots using 0.01 and 100 as values of `gamma` also.  Compare classification boundaries between these three plots and describe how they are impacted by the change in the value of `gamma`.  Can you trace it back to the role of `gamma` in the equation introducing it with the radial kernel in ISLR?

### Solution

```{r radialPlots}
plot(svm(auth~.,data=dbaDat[,-(3:4)],kernel="radial",cost=1,gamma=1),data=dbaDat[,-(3:4)])
plot(svm(auth~.,data=dbaDat[,-(3:4)],kernel="radial",cost=1,gamma=0.01),data=dbaDat[,-(3:4)])
plot(svm(auth~.,data=dbaDat[,-(3:4)],kernel="radial",cost=1,gamma=100),data=dbaDat[,-(3:4)])
```

Increase in the values of $\gamma$ is associated with the increase in the number of support vectors and progressively more non-linear decision surfaces. This is the result of exponential decrease in the relative contributions to the radial kernel of more distant points (e.g. Eq.9.24 in ISLR), so that only most immediate neighbors in the training data have any impact on the classification of any given test observation when $\gamma$ is high.

## Sub-problem 4b (10 points): test error for SVM with radial kernel

Similar to how it was done above for support vector classifier (and KNN), set up a resampling process that will repeatedly: a) split the entire dataset (using all attributes as predictors) into training and test datasets, b) use `tune` function to determine optimal values of `cost` and `gamma` and c) calculate test error using these values of `cost` and `gamma`.  You can start with `cost=c(1,2,5,10,20)` and `gamma=c(0.01,0.02,0.05,0.1,0.2)` as starting ranges to evaluate by `tune`, but please feel free to experiment with different sets of values and discuss the results of it and how you would go about selecting those ranges starting from scratch.  Present resulting test error graphically, compare it to that of support vector classifier (with linear kernel), random forest and KNN classifiers obtained above and discuss results of these comparisons. 

### Solution

```{r radialTest}
dfTmp <- NULL
for ( iSim in 1:10 ) {
  trainIdx <- sample(nrow(dbaDat),nrow(dbaDat),replace=TRUE)
  # radial:
  svmTuneRes <- tune(svm,auth~.,data=dbaDat[trainIdx,],kernel="radial",ranges=list(cost=c(1,2,5,10,20),gamma=c(0.01,0.02,0.05,0.1)))
  tblTmp <- table(dbaDat[-trainIdx,"auth"],predict(svmTuneRes$best.model,newdata=dbaDat[-trainIdx,]))
  #print(tblTmp)
  #cat(svmTuneRes$best.parameters[1,"cost"],svmTuneRes$best.parameters[1,"gamma"],c(tblTmp[1,2]/sum(tblTmp[1,]),tblTmp[2,1]/sum(tblTmp[2,]),1-sum(diag(tblTmp))/sum(tblTmp)),fill=TRUE)
  dfTmp <- rbind(dfTmp,data.frame(kernel="radial",attr=c("cost","gamma","err0","err1","errTot"),value=c(svmTuneRes$best.parameters[1,"cost"],svmTuneRes$best.parameters[1,"gamma"],tblTmp[1,2]/sum(tblTmp[1,]),tblTmp[2,1]/sum(tblTmp[2,]),1-sum(diag(tblTmp))/sum(tblTmp))))
}
ggplot(dfTmp,aes(x=attr,y=value))+geom_jitter()+scale_y_log10()
ddply(dfTmp,"attr",function(x)mean(x[,"value"]))
ddply(dfTmp,"attr",function(x)median(x[,"value"]))
```

Results shown above indicate that SVM with radial kernel can yield perfect accuracy on the test data outperforming for this dataset SVM with linear kernel, random forest and KNN.  Corresponding values of `cost` and `gamma` selected by `tune` are approximately 10-20 and 0.02-0.05, but it is likely that such performance can be also observed for their values outside of this range.

# Extra 8 points problem: SVM with polynomial kernel

Repeat what was done above (plots of decision boundaries for various interesting values of tuning parameters and test error for their best values estimated from training data) using `kernel="polynomial"`.   Determine ranges of `cost` and `gamma` to be evaluated by `tune`.  Present and discuss resulting test error and how it compares to linear and radial kernels and those of random forest and SVM.

## Solution

```{r polynomPlots}
plot(svm(auth~.,data=dbaDat[,-(3:4)],kernel="polynomial",cost=1,gamma=0.5,coef0=0,degree=2),data=dbaDat[,-(3:4)])
plot(svm(auth~.,data=dbaDat[,-(3:4)],kernel="polynomial",cost=1,gamma=0.5,coef0=1,degree=2),data=dbaDat[,-(3:4)])
plot(svm(auth~.,data=dbaDat[,-(3:4)],kernel="polynomial",cost=1,gamma=0.5,coef0=1,degree=3),data=dbaDat[,-(3:4)])
plot(svm(auth~.,data=dbaDat[,-(3:4)],kernel="polynomial",cost=1,gamma=0.1,coef0=1,degree=3),data=dbaDat[,-(3:4)])
plot(svm(auth~.,data=dbaDat[,-(3:4)],kernel="polynomial",cost=0.1,gamma=0.5,coef0=1,degree=3),data=dbaDat[,-(3:4)])
svm(auth~.,data=dbaDat,kernel="polynomial",cost=1,gamma=0.5,coef0=1,degree=3)
```

Setting `coef0` parameter to non-zero value appears to be very important for the performance of SVM with polynomial kernel on this dataset.  Increase in `degree` values appears to increase non-linearity of the decision surface. Parameters `cost` and `gamma` further influence the shape of the margin.

```{r polynomTest}
dfTmp <- NULL
for ( iSim in 1:10 ) {
  trainIdx <- sample(nrow(dbaDat),nrow(dbaDat),replace=TRUE)
  # polynomial:
  svmTuneRes <- tune(svm,auth~.,data=dbaDat[trainIdx,],kernel="polynomial",tunecontrol=tune.control(cross=5),ranges=list(cost=1:3,degree=2:4,coef0=c(0,0.5,1),gamma=c(0.2,0.5,1.0)))
  tblTmp <- table(dbaDat[-trainIdx,"auth"],predict(svmTuneRes$best.model,newdata=dbaDat[-trainIdx,]))
  #print(tblTmp)
  #print(svmTuneRes$best.parameters)
  dfTmp <- rbind(dfTmp,data.frame(kernel="polynom",attr=c("cost","degree","coef0","gamma","err0","err1","totErr"),value=c(as.numeric(svmTuneRes$best.parameters[1,]),tblTmp[1,2]/sum(tblTmp[1,]),tblTmp[2,1]/sum(tblTmp[2,]),1-sum(diag(tblTmp))/sum(tblTmp))))
}
ggplot(dfTmp,aes(x=attr,y=value))+geom_jitter()+scale_y_log10(breaks=c(0.1,0.2,0.5,1,2,5))
ddply(dfTmp,"attr",function(x)mean(x[,"value"]))
ddply(dfTmp,"attr",function(x)median(x[,"value"]))
```

For `coef0`, `cost`, `degree` and `gamma` around 0.5, 2, 2 and 0.2 respectively SVM with polynomial kernel can achieve 100% accuracy on test data for this dataset.